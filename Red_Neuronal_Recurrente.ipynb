{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK8eUOQU7q2V"
   },
   "source": [
    "# Redes Neuronales Recurrentes\n",
    "\n",
    "By Elías Jesús Ventura-Molina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### Importar TensorFlow 2.0  y otras librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zWrJnG1jZd00"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHDoRoc5PKWz"
   },
   "source": [
    "### Obtiene el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pD_55cOxLkAb",
    "outputId": "1a80fe82-fbb0-4b06-f55f-9e5fdd7643e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto:        203249 carácteres\n",
      "El texto está compuesto de estos 92 carácteres:\n",
      "['\\n', '\\r', ' ', '!', '\"', '#', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'ÿ', 'Š', '‡', '…']\n"
     ]
    }
   ],
   "source": [
    "# Ruta donde se encuentra el archivo de texto\n",
    "path_to_fileDL = 'TextoBase.txt'\n",
    "\n",
    "# Se lee el archivo\n",
    "text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n",
    "print('Longitud del texto:        {} carácteres'.format(len(text)))\n",
    "\n",
    "#Se obtiene todos los caracteres que forman el archivo\n",
    "# Y despues se ordenan\n",
    "vocab = sorted(set(text))\n",
    "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
    "print (vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSGY442m-yXc"
   },
   "source": [
    "## Pre-procesamiento datos\n",
    "\n",
    "Las redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IalZLbvOzf-F",
    "outputId": "fe4f35ef-452a-4955-fb81-ae4f40cd1ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  '\\n':   0,\n",
      "  '\\r':   1,\n",
      "  ' ' :   2,\n",
      "  '!' :   3,\n",
      "  '\"' :   4,\n",
      "  '#' :   5,\n",
      "  '%' :   6,\n",
      "  \"'\" :   7,\n",
      "  '(' :   8,\n",
      "  ')' :   9,\n",
      "  '*' :  10,\n",
      "  '+' :  11,\n",
      "  ',' :  12,\n",
      "  '-' :  13,\n",
      "  '.' :  14,\n",
      "  '/' :  15,\n",
      "  '0' :  16,\n",
      "  '1' :  17,\n",
      "  '2' :  18,\n",
      "  '3' :  19,\n",
      "  '4' :  20,\n",
      "  '5' :  21,\n",
      "  '6' :  22,\n",
      "  '7' :  23,\n",
      "  '8' :  24,\n",
      "  '9' :  25,\n",
      "  ':' :  26,\n",
      "  ';' :  27,\n",
      "  '<' :  28,\n",
      "  '=' :  29,\n",
      "  '>' :  30,\n",
      "  '?' :  31,\n",
      "  '@' :  32,\n",
      "  'A' :  33,\n",
      "  'B' :  34,\n",
      "  'C' :  35,\n",
      "  'D' :  36,\n",
      "  'E' :  37,\n",
      "  'F' :  38,\n",
      "  'G' :  39,\n",
      "  'H' :  40,\n",
      "  'I' :  41,\n",
      "  'J' :  42,\n",
      "  'K' :  43,\n",
      "  'L' :  44,\n",
      "  'M' :  45,\n",
      "  'N' :  46,\n",
      "  'O' :  47,\n",
      "  'P' :  48,\n",
      "  'Q' :  49,\n",
      "  'R' :  50,\n",
      "  'S' :  51,\n",
      "  'T' :  52,\n",
      "  'U' :  53,\n",
      "  'V' :  54,\n",
      "  'W' :  55,\n",
      "  'X' :  56,\n",
      "  'Y' :  57,\n",
      "  '[' :  58,\n",
      "  ']' :  59,\n",
      "  '_' :  60,\n",
      "  'a' :  61,\n",
      "  'b' :  62,\n",
      "  'c' :  63,\n",
      "  'd' :  64,\n",
      "  'e' :  65,\n",
      "  'f' :  66,\n",
      "  'g' :  67,\n",
      "  'h' :  68,\n",
      "  'i' :  69,\n",
      "  'j' :  70,\n",
      "  'k' :  71,\n",
      "  'l' :  72,\n",
      "  'm' :  73,\n",
      "  'n' :  74,\n",
      "  'o' :  75,\n",
      "  'p' :  76,\n",
      "  'q' :  77,\n",
      "  'r' :  78,\n",
      "  's' :  79,\n",
      "  't' :  80,\n",
      "  'u' :  81,\n",
      "  'v' :  82,\n",
      "  'w' :  83,\n",
      "  'x' :  84,\n",
      "  'y' :  85,\n",
      "  'z' :  86,\n",
      "  '\\xad':  87,\n",
      "  'ÿ' :  88,\n",
      "  'Š' :  89,\n",
      "  '‡' :  90,\n",
      "  '…' :  91,\n"
     ]
    }
   ],
   "source": [
    "# Funcion que asigna un valor numerico a cada caracter\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "# Funcion que devuelve caracter con base en un numero  \n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "#Se  imprime las asocianes caracter-numero\n",
    "for char,_ in zip(char2idx, range(len(vocab))):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0SXxlLH_DfC"
   },
   "source": [
    "Convierte todo el conjutno de datos a su representación numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ML-DuUyi_aHy"
   },
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTui3Pg8O29N"
   },
   "source": [
    "Ejemplo de transformación de texto a su representación numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1VKcQHcymwb",
    "outputId": "d8e28d9a-4c3b-44db-e8c7-f293948d4c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texto: 'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fun'\n",
      "array([48, 78, 75, 72, 75, 67, 75,  1,  0, 37, 74,  2, 17, 25, 21, 19, 12,\n",
      "        2, 41, 79, 61, 61, 63,  2, 33, 79, 69, 73, 75, 82,  2, 76, 81, 62,\n",
      "       72, 69, 63, 75,  2, 51, 65, 67, 81, 74, 64, 61,  2, 38, 81, 74])\n"
     ]
    }
   ],
   "source": [
    "print ('texto: {}'.format(repr(text[:50])))\n",
    "print ('{}'.format(repr(text_as_int[:50])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Preparar los datos para entrenar la RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw_jjg9k_cNJ"
   },
   "source": [
    "Para entrenar el modelo prepararemos unas secuencias de caracteres como entradas y salida de un tamaño determinado. \n",
    "\n",
    "\n",
    "Empezamos dividiendo el texto en secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0UHJDA39zf-O"
   },
   "outputs": [],
   "source": [
    "#Se crea un iterados sobre los datos\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "#Tamaño de la secuencia (puede ser modificado) \n",
    "seq_length = 100\n",
    "#Genera las secuencias\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5rdvZsB_157"
   },
   "source": [
    "Ejemplo de secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4hkDU3i7ozi",
    "outputId": "1c7fe1cc-c614-4102-e238-126124313e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n",
      "'(o el decimotercero segun otras fuentes, este es un tema de debate). En Segunda Fundacion aparece por'\n",
      "' primera vez Arkady Darell, uno de los principales personajes de la parte final de la saga. En su pri'\n",
      "'mera escena, Arkady, que tiene 14 anos, esta haciendo sus tareas escolares. En concreto, una redaccio'\n",
      "'n que lleva por titulo ?El Futuro del Plan Sheldon?. Para hacer la redaccion, Arkady esta utilizando '\n",
      "'un ?transcriptor?,un dispositivo que convierte su voz en palabras escritas. Este tipo de dispositivo,'\n",
      "' que para Isaac Asimov era ciencia ficcion en 1953, lo tenemos al alcance de la mano en la mayoria de'\n",
      "' nuestros smartphones, y el Deep Learning es uno de los responsables de que ya tengamos este tipo de '\n",
      "'aplicaciones, siendo la tecnologia otro de ellos.En la actualidad disponemos de GPUs (Graphics Proces'\n",
      "'sor Units), que solo cuestan alrededor de 100 euros, que estarian en la lista del Top500 hace unos po'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(10):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eH99UaQt_-uO"
   },
   "source": [
    "De esta secuencia se obtiene el conjunto de datos de training que contenga tanto los datos de entrada (desde la posición 0 a la 99) como los datos de salida (desde la posición 1 a la 100). \n",
    "\n",
    "La idea es crear patrones donde las entradas y salidas contengan la misma longitud de texto, excepto que la salida es el desplazamiento de la entranada en un carácter a la derecha. \n",
    "Ejemplo: la secuencia de entrada será “Hol”, y la de salida será “ola”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "# Se crea la función que genera el conjunto de entrada así como el conjunto de \n",
    "# salida con base en una secuencia\n",
    "def split_input_target(chunk):\n",
    "  #Define el conjunto de entrada\n",
    "    input_text = chunk[:-1]\n",
    "  #Define el conjunto de salida\n",
    "    target_text = chunk[1:]\n",
    "  #Retorna ambos conjuntos\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uo8HzC9BdMS"
   },
   "source": [
    "Ejemplo de una secuencia generada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNbw-iR0ymwj",
    "outputId": "2556efca-e57e-451e-ad56-6d5059fc35b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion'\n",
      "Target data: 'rologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvVPV0svBkyc"
   },
   "source": [
    "Información del sencuencias generadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eBu9WZG84i0",
    "outputId": "9a9f7c04-6573-4441-a7ac-2ed60cf7b277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print (dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb7B5oW6BzIo"
   },
   "source": [
    "Se define parametros de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2pGotuNzf-S",
    "outputId": "97be7c01-3284-4952-d5b8-f9fe2fcab225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "#Tamaño del batch\n",
    "BATCH_SIZE = 64\n",
    "#Tamaño del buffer\n",
    "BUFFER_SIZE = 10000\n",
    "# Se agrupo los datos en batch y\n",
    "#Se realiza un acomodo aleatorio\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print (dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0R0FJ4afxGiK"
   },
   "source": [
    "La red esta compuesta por 3 capas:\n",
    "\n",
    "- La primera capa es de tipo Word Embedding; mapea cada carácter de entrada en un vector Embedding.\n",
    "Parametros: \n",
    "  - Tamaño del vocabulario, indicando cuantos vectores Embedding tendrá la capa\n",
    "  -Dimension del  vector Embedding \n",
    "  -Tamaño del batch \n",
    "\n",
    "- La segunda capa es de tipo RRN. Parametros: \n",
    "  - Número de neuronas recurrentes\n",
    "  - Return_sequencese indica que queremos predecir el carácter siguiente a todos los caracteres de entrada, no solo el siguiente al último carácter.\n",
    "  - Stateful indica el uso de las capacidades de memoria de la red entre batche; si está a true está indicando para cada batch se mantendrán las actualizaciones hechas durante la ejecución del bach anterior.\n",
    "  - recurrent_kernel indica cómo se deben inicializar los pesos de las matrices internas de la red. En este caso usamos la distribución uniforme glorot_uniform, habitual en estos casos.\n",
    "\n",
    "- La última capa es de tipo Dense. Parametros:\n",
    "    - Units indica cuantas neuronas tendrá la capa y que nos marcará la dimensión de la salida. En nuestro caso será igual al tamaño de nuestro vocabulario (vocab_size).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "# Función que crea el modelo de la red\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "#Se difine parametros del modelo\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "#Se crea el modelo\n",
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpHGXDMcZ0Zt",
    "outputId": "89aae67f-c16c-4ce8-a236-f68938ec38cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           23552     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 92)            94300     \n",
      "=================================================================\n",
      "Total params: 5,364,828\n",
      "Trainable params: 5,364,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Se visualiza la estructura del modelo:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7I-ZWYt3-xy"
   },
   "source": [
    "La función de perdida, también conocida como función de costo, es la función que nos dice que tan buena es la red neuronal, un resultado alto indica que la red neuronal tiene un desempeño pobre y un resultado bajo indica que la red neuronal esta haciendo un buen trabajo. Esta es la función que optimizamos o minimizamos cuando realizamos el backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4HrXTACTdzY-"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC9v8jZt4Fn0"
   },
   "source": [
    "Se compila el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "Configuración de los *checkpoints*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    " # directorio\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# nombre fichero\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "*Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UK-hmKjYVoll",
    "outputId": "c41d80d0-49c6-4acf-e815-b950c24e28d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 3.2853\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 2.8615\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 2.5394\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 2.3220\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 2.1973\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 2.1055\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 2.0138\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.9267\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.8298\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.7427\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 1.6571\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5767\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.5010\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.4328\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.3717\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.3181\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.2692\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.2226\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.1815\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.1425\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 1.1105\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.0770\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.0470\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 1.0171\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.9879\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.9576\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.9320\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.9058\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.8784\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.8520\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.8255\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.8024\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.7765\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.7540\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.7254\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.7025\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.6804\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.6535\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.6291\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.6064\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.5822\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.5580\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.5362\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.5167\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.4976\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.4759\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.4547\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.4424\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.4226\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.4054\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Prueba del modelo -  Generación de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djST08az4ZyX"
   },
   "source": [
    "Se crea el modelo con los últimos pesos generado s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zk2WJ2-XjkGz",
    "outputId": "35f18591-d45c-46bc-97eb-56a9c324fcbe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./training_checkpoints/ckpt_50'"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se obtiene los ultimos pesos generado\n",
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "# Se define los parametros del modelo\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# Se carga los ultimos pesos\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# Se construye los modelos\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wV9qoUn84tHo"
   },
   "source": [
    "\n",
    "Ahora que tenemos el modelo entrenado y preparado para usar, generaremos texto a partir de una palabra de partida con el siguiente código:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "\n",
    "#definir el número de caracteres a predecir \n",
    "  num_generate = 500\n",
    "#convertir la palabra inicial a su correspondiente representación numérica \n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "#preparan lo tensores necesarios\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "\n",
    "\n",
    "#Usando la misma idea del código original char-rnn de Andrey Karpathy,\n",
    "#se usa una variable temperature para decidir que tan permisibo se comporte \n",
    "#el modelo.En  este ejemplo la hemos inicializado a 0.5:\n",
    "  temperature = 0.5\n",
    "#Con “temperaturas altas” (hasta 1) se permitirá más creatividad al modelo\n",
    "#para generar texto pero a costa de más errores (por ejemplo, errores ortográficos, etc.). \n",
    "# Mientras que con “temperaturas bajas” habrá menos errores pero el modelo mostrará poca creatividad.\n",
    "\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "    #Realiza la prediccion \n",
    "      predictions = model(input_eval)\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    #Se aplica la temperatura a la predicción \n",
    "      predictions = predictions / temperature\n",
    "   #Se usa una distribución categórica para calcular el índice del carácter predicho:\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    #Este carácter acabado de predecir se usa como nuestra próxima entrada al modelo\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  #La prediccion es almacenada es una variable\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zijkRThx8a5W"
   },
   "source": [
    "### Ejemplos de generación de texto\n",
    "\n",
    "Los siguientes son ejemplos de corrida de la función anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsNst9-GeiZo",
    "outputId": "527128e5-95a3-48d8-ee30-b75375680016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo deben ser derivablos por los datos de entrenamiento para almacenar los datos disponibles en total de cada uno de ellos separadamente, la capa de pooling con una se de la pantalla de una funcion que adante la probabilidad esto es una experto en Machine Learning, pero esta visto que estos ellos despues de entrada.\r\n",
      "*  frece de GPUs esta informacion para tiene un supercomputacion presentan un ejemplo de red neuronal convolucional que el proceso de aprendizaje por un escalar conocido como el parame\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"modelo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFOd58ksem1a",
    "outputId": "7c3e26ec-0ff3-4a5d-eb7b-83e90e1af8ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activacion para entrenar a los modelos de inteligencia artificial en general, en concreto, del modelo en particular del tema del libro una vez incluidos en la entrada de 28?28 pixeles y una ventana de 5?5 en la capa de pooling contendra una red neuronal artificial con el metodo summary() que retorna el metodo summary() podemos encontrar todos los tipos de problema. Adjunto al codigo del libro hablaremos mas de un tensor 3D de puesto esta es que estamas habitualmente las redes neuronales convolucionales po\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"activacion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktovv0RFhrkn",
    "outputId": "506792e0-b5c8-4710-cff1-f39147d28e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perro descargar de GitHub localmente a probar los hallanzos esta compuesto por multiples capas ocultas (hidden layers) y podemos tener hasta ocho neuronas tecnicas de redes neuronales convolucionales para que los valores iniciales de la primera capa de pooling, que sueve elemento el lector, vientros de entrada, se han refire con el tema,  desde hace un tiempo en el resultado apartado varias operaciones por se este es demasiado para tar entender los conceptos basicos de este si nos en este caso, el mod\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"perro\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Red Neuronal Recurrente",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
